{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:56:26.032849Z",
     "start_time": "2025-04-08T15:41:40.821147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rlr_validate_custom import rlr_validate_custom\n",
    "from sklearn import model_selection\n",
    "from ann_validate import ann_validate\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "url = \"https://hastie.su.domains/ElemStatLearn/datasets/SAheart.data\"\n",
    "\n",
    "# Load the SAheart dataset\n",
    "df = pd.read_csv(url, index_col='row.names')\n",
    "\n",
    "# Convert binary text data to numbered categories\n",
    "df['famhist'] = pd.Categorical(df['famhist']).codes\n",
    "\n",
    "# Extract the target attribute, and remove it from the training data\n",
    "y = np.asarray(np.asmatrix(df[\"typea\"].values).T).squeeze()\n",
    "df = df.drop(columns=[\"typea\"])\n",
    "\n",
    "# Attribute names\n",
    "attributeNames = list(map(lambda x: x.capitalize(), df.columns.tolist()))\n",
    "\n",
    "# Convert the training data to a numpy array\n",
    "X = df.to_numpy()\n",
    "N, M = X.shape\n",
    "\n",
    "X = zscore(X, ddof=1)  # Mean = 0, Std = 1\n",
    "y = zscore(y, ddof=1)  # Mean = 0, Std = 1\n",
    "\n",
    "# ---\n",
    "# End of data loading\n",
    "# ---\n",
    "\n",
    "\n",
    "# Add offset attribute\n",
    "X = np.concatenate((np.ones((X.shape[0], 1)), X), 1)\n",
    "attributeNames = [\"Offset\"] + attributeNames\n",
    "M = M + 1\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 10\n",
    "CV = model_selection.KFold(K, shuffle=True)\n",
    "# CV = model_selection.KFold(K, shuffle=False)\n",
    "\n",
    "lambda_count = 20\n",
    "\n",
    "# Values of lambda\n",
    "lambdas = np.logspace(0, 4, lambda_count)\n",
    "n_hidden_units_range = range(1, 30)\n",
    "max_iter = 10000\n",
    "\n",
    "#Actual y-s\n",
    "y_true = []\n",
    "\n",
    "# Linear regression\n",
    "lr_error_train = np.empty((K, 1))\n",
    "lr_error_test = np.empty((K, 1))\n",
    "best_lambda = np.empty((K, 1))\n",
    "y_est_lr = []\n",
    "\n",
    "# ANN\n",
    "ann_error_train = np.empty((K, 1))\n",
    "ann_error_test = np.empty((K, 1))\n",
    "best_hidden_units = np.empty((K, 1))\n",
    "y_est_ann = []\n",
    "\n",
    "# Baseline\n",
    "baseline_error_test = np.empty((K, 1))\n",
    "y_est_base = []\n",
    "\n",
    "\n",
    "w_rlr = np.empty((M, K))\n",
    "mu = np.empty((K, M - 1))\n",
    "sigma = np.empty((K, M - 1))\n",
    "w_noreg = np.empty((M, K))\n",
    "\n",
    "k = 0\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    innerCV = model_selection.KFold(K, shuffle=True)\n",
    "\n",
    "    y_true.append(y_test)\n",
    "\n",
    "\n",
    "    # ----\n",
    "    # Linear regression\n",
    "    # ----\n",
    "\n",
    "    (   opt_val_err,\n",
    "        opt_lambda,\n",
    "        mean_w_vs_lambda,\n",
    "        train_err_vs_lambda,\n",
    "        test_err_vs_lambda,\n",
    "    ) = rlr_validate_custom(X_train, y_train, lambdas, K, innerCV)\n",
    "\n",
    "    # Standardize outer fold based on training set, and save the mean and standard\n",
    "    # deviations since they're part of the model (they would be needed for\n",
    "    # making new predictions) - for brevity we won't always store these in the scripts\n",
    "    mu[k, :] = np.mean(X_train[:, 1:], 0)\n",
    "    sigma[k, :] = np.std(X_train[:, 1:], 0)\n",
    "\n",
    "    X_train[:, 1:] = (X_train[:, 1:] - mu[k, :]) / sigma[k, :]\n",
    "    X_test[:, 1:] = (X_test[:, 1:] - mu[k, :]) / sigma[k, :]\n",
    "\n",
    "    Xty = X_train.T @ y_train\n",
    "    XtX = X_train.T @ X_train\n",
    "\n",
    "    # Estimate weights for the optimal value of lambda, on entire training set\n",
    "    lambdaI = opt_lambda * np.eye(M)\n",
    "    lambdaI[0, 0] = 0  # Do no regularize the bias term\n",
    "    w_rlr[:, k] = np.linalg.solve(XtX + lambdaI, Xty).squeeze()\n",
    "\n",
    "    # Compute mean squared error with regularization with optimal lambda\n",
    "    lr_error_train[k] = (\n",
    "        np.square(y_train - X_train @ w_rlr[:, k]).sum(axis=0) / y_train.shape[0]\n",
    "    )\n",
    "    lr_error_test[k] = (\n",
    "        np.square(y_test - X_test @ w_rlr[:, k]).sum(axis=0) / y_test.shape[0]\n",
    "    )\n",
    "    best_lambda[k] = opt_lambda\n",
    "    y_est_lr.append(X_test @ w_rlr[:, k])\n",
    "\n",
    "    # ----\n",
    "    # ANN\n",
    "    # ----\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    models = np.empty((len(n_hidden_units_range),), dtype=object)\n",
    "\n",
    "    # Generate out models with different number of hidden units\n",
    "    for i, n_hidden_units in enumerate(n_hidden_units_range):\n",
    "        model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(M, n_hidden_units),  # Input layer\n",
    "            torch.nn.Tanh(),  # Hidden activation (ReLU is also good)\n",
    "            torch.nn.Linear(n_hidden_units, 1)   # Output layer (NO SIGMOID for regression)\n",
    "        )\n",
    "        models[i] = model\n",
    "\n",
    "    (\n",
    "        opt_val_err,\n",
    "        opt_model_index,\n",
    "        opt_model,\n",
    "        opt_network,\n",
    "        train_err_vs_lambda,\n",
    "        test_err_vs_lambda\n",
    "        #This does a folding cross-validation\n",
    "    ) = ann_validate(torch.Tensor(X_train), torch.Tensor(y_train), models, loss_fn, 1, max_iter, K, innerCV)\n",
    "\n",
    "    #ann_error_train[k] = np.square(y_train-opt_network(torch.Tensor(X_train)).detach().numpy()).sum()/y_train.shape[0]\n",
    "    #ann_error_test[k] = np.square(y_train-opt_network(torch.Tensor(X_train)).detach().numpy()).sum()/y_train.shape[0]\n",
    "\n",
    "    ann_error_train[k] = train_err_vs_lambda[opt_model_index]\n",
    "    ann_error_test[k] = test_err_vs_lambda[opt_model_index]\n",
    "    best_hidden_units[k] = n_hidden_units_range[opt_model_index]\n",
    "    y_est_ann.append(opt_network(torch.Tensor(X_test)).detach().numpy())\n",
    "\n",
    "    # ----\n",
    "    # Baseline\n",
    "    # ----\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Compute the mean of y_train as the baseline prediction\n",
    "    y_baseline = np.mean(y_train)\n",
    "\n",
    "    # Predict the same mean value for all test samples\n",
    "    y_pred_baseline = np.full_like(y_test, y_baseline)\n",
    "\n",
    "    # Compute and store the MSE\n",
    "    mse = mean_squared_error(y_test, y_pred_baseline)\n",
    "    baseline_error_test[k] = mse\n",
    "    y_est_base.append(y_pred_baseline)\n",
    "\n",
    "\n",
    "    k += 1\n"
   ],
   "id": "a038ce12b7806ffc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([373])) that is different to the input size (torch.Size([373, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "5it [00:46,  9.25s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:29,  8.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([373])) that is different to the input size (torch.Size([373, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "5it [00:44,  9.23s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:34,  9.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:54,  8.97s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:28,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:53,  9.02s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:33,  9.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:56,  9.40s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:31,  9.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:57,  9.10s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:28,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:49,  8.46s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:23,  8.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:49,  8.27s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:21,  8.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:51,  8.55s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:28,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:48,  8.32s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:24,  8.49s/it]\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:59:53.408609Z",
     "start_time": "2025-04-08T15:59:53.399496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = pd.DataFrame({\n",
    "    \"h\" : best_hidden_units.flatten(),\n",
    "    \"ann_error_test\": ann_error_test.flatten(),\n",
    "\n",
    "    \"lambda\": best_lambda.flatten(),\n",
    "    \"lr_error_test\": lr_error_test.flatten(),\n",
    "\n",
    "    \"baseline_error_test\": baseline_error_test.flatten(),\n",
    "})\n",
    "results"
   ],
   "id": "606c6651a5c81d4c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      h  ann_error_test      lambda  lr_error_test  baseline_error_test\n",
       "0   9.0        0.981690   78.475997       1.095045             1.111682\n",
       "1  20.0        0.997443   78.475997       1.014643             0.998448\n",
       "2   5.0        1.024234  127.427499       0.739055             0.748277\n",
       "3   6.0        1.000396   29.763514       0.988991             0.948298\n",
       "4  17.0        0.991316   78.475997       0.990541             1.057561\n",
       "5  23.0        0.988164  127.427499       1.026781             1.053704\n",
       "6  13.0        1.000706  335.981829       0.890256             0.917386\n",
       "7  10.0        0.977799  127.427499       1.140282             1.186476\n",
       "8  14.0        0.982276   78.475997       1.100426             1.172839\n",
       "9  11.0        1.013012   78.475997       0.790712             0.838251"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>ann_error_test</th>\n",
       "      <th>lambda</th>\n",
       "      <th>lr_error_test</th>\n",
       "      <th>baseline_error_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.981690</td>\n",
       "      <td>78.475997</td>\n",
       "      <td>1.095045</td>\n",
       "      <td>1.111682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.997443</td>\n",
       "      <td>78.475997</td>\n",
       "      <td>1.014643</td>\n",
       "      <td>0.998448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.024234</td>\n",
       "      <td>127.427499</td>\n",
       "      <td>0.739055</td>\n",
       "      <td>0.748277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000396</td>\n",
       "      <td>29.763514</td>\n",
       "      <td>0.988991</td>\n",
       "      <td>0.948298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.991316</td>\n",
       "      <td>78.475997</td>\n",
       "      <td>0.990541</td>\n",
       "      <td>1.057561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.988164</td>\n",
       "      <td>127.427499</td>\n",
       "      <td>1.026781</td>\n",
       "      <td>1.053704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.000706</td>\n",
       "      <td>335.981829</td>\n",
       "      <td>0.890256</td>\n",
       "      <td>0.917386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.977799</td>\n",
       "      <td>127.427499</td>\n",
       "      <td>1.140282</td>\n",
       "      <td>1.186476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.982276</td>\n",
       "      <td>78.475997</td>\n",
       "      <td>1.100426</td>\n",
       "      <td>1.172839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.013012</td>\n",
       "      <td>78.475997</td>\n",
       "      <td>0.790712</td>\n",
       "      <td>0.838251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:00:15.447357Z",
     "start_time": "2025-04-08T16:00:15.444630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "latex_table = r\"\"\"\\begin{tabular}{c|cc|cc|c}\n",
    "\\toprule\n",
    "\\textbf{Outer fold} & \\multicolumn{2}{c|}{\\textbf{ANN}} & \\multicolumn{2}{c|}{\\textbf{Linear regression}} & \\textbf{baseline} \\\\\n",
    "$i$ & $h_i^*$ & $E_i^{\\text{test}}$ & $\\lambda_i^*$ & $E_i^{\\text{test}}$ & $E_i^{\\text{test}}$ \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for i, row in results.iterrows():\n",
    "    latex_table += f\"{i+1} & {row['h']} & {row['ann_error_test']:.3f} & {row['lambda']:.2f} & {row['lr_error_test']:.3f} & {row['baseline_error_test']:.3f} \\\\\\\\\\n\"\n",
    "\n",
    "latex_table += r\"\\bottomrule\" + \"\\n\" + r\"\\end{tabular}\"\n",
    "print(latex_table)\n"
   ],
   "id": "7e803c2be80e33ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|cc|cc|c}\n",
      "\\toprule\n",
      "\\textbf{Outer fold} & \\multicolumn{2}{c|}{\\textbf{ANN}} & \\multicolumn{2}{c|}{\\textbf{Linear regression}} & \\textbf{baseline} \\\\\n",
      "$i$ & $h_i^*$ & $E_i^{\\text{test}}$ & $\\lambda_i^*$ & $E_i^{\\text{test}}$ & $E_i^{\\text{test}}$ \\\\\n",
      "\\midrule\n",
      "1 & 9.0 & 0.982 & 78.48 & 1.095 & 1.112 \\\\\n",
      "2 & 20.0 & 0.997 & 78.48 & 1.015 & 0.998 \\\\\n",
      "3 & 5.0 & 1.024 & 127.43 & 0.739 & 0.748 \\\\\n",
      "4 & 6.0 & 1.000 & 29.76 & 0.989 & 0.948 \\\\\n",
      "5 & 17.0 & 0.991 & 78.48 & 0.991 & 1.058 \\\\\n",
      "6 & 23.0 & 0.988 & 127.43 & 1.027 & 1.054 \\\\\n",
      "7 & 13.0 & 1.001 & 335.98 & 0.890 & 0.917 \\\\\n",
      "8 & 10.0 & 0.978 & 127.43 & 1.140 & 1.186 \\\\\n",
      "9 & 14.0 & 0.982 & 78.48 & 1.100 & 1.173 \\\\\n",
      "10 & 11.0 & 1.013 & 78.48 & 0.791 & 0.838 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:00:59.938354Z",
     "start_time": "2025-04-08T16:00:59.928960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dtuimldmtools.statistics.statistics import ttest_twomodels\n",
    "import numpy as np\n",
    "\n",
    "# Compute the Jeffreys interval\n",
    "alpha = 0.05\n",
    "rho = 1/K\n",
    "\n",
    "# Convert lists to numpy arrays and stack them properly\n",
    "y_true_array = np.concatenate(y_true).ravel()\n",
    "y_est_ANN_array = np.concatenate(y_est_ann).ravel()\n",
    "y_est_LR_array = np.concatenate(y_est_lr).ravel()\n",
    "y_est_base_array = np.concatenate(y_est_base).ravel()\n",
    "\n",
    "def run_ttest(y_true, y_A, y_B):\n",
    "    mean_diff, confidence_interval, p_value =  ttest_twomodels(y_true, y_A, y_B, alpha=alpha)\n",
    "    return mean_diff, confidence_interval, p_value\n",
    "\n",
    "# Perform t-tests\n",
    "mean_diff_ANN_LR, CI_ANN_LR, p_ANN_LR = run_ttest(y_true_array, y_est_ANN_array, y_est_LR_array)\n",
    "mean_diff_ANN_base, CI_ANN_base, p_ANN_base = run_ttest(y_true_array, y_est_ANN_array, y_est_base_array)\n",
    "mean_diff_LR_base, CI_LR_base, p_LR_base = run_ttest(y_true_array, y_est_LR_array, y_est_base_array)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Comparison\": [\"ANN vs LR\", \"ANN vs Baseline\", \"LR vs Baseline\"],\n",
    "    \"Mean Difference\": [mean_diff_ANN_LR, mean_diff_ANN_base, mean_diff_LR_base],\n",
    "    \"Confidence Interval Min\": [CI_ANN_LR[0], CI_ANN_base[0], CI_LR_base[0]],\n",
    "    \"Confidence Interval Max\": [CI_ANN_LR[1], CI_ANN_base[1], CI_LR_base[1]],\n",
    "    \"p-value\": [p_ANN_LR, p_ANN_base, p_LR_base]\n",
    "})"
   ],
   "id": "f771763f6abc7930",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:01:01.612449Z",
     "start_time": "2025-04-08T16:01:01.605756Z"
    }
   },
   "cell_type": "code",
   "source": "print(results_df.to_latex())",
   "id": "6431a997e20cbe42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      " & Comparison & Mean Difference & Confidence Interval Min & Confidence Interval Max & p-value \\\\\n",
      "\\midrule\n",
      "0 & ANN vs LR & 0.011330 & -0.005091 & 0.027750 & 0.175793 \\\\\n",
      "1 & ANN vs Baseline & 0.003649 & -0.000059 & 0.007357 & 0.053741 \\\\\n",
      "2 & LR vs Baseline & -0.007681 & -0.023887 & 0.008526 & 0.352174 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
