{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:56:26.032849Z",
     "start_time": "2025-04-08T15:41:40.821147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rlr_validate_custom import rlr_validate_custom\n",
    "from sklearn import model_selection\n",
    "from ann_validate import ann_validate\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "url = \"https://hastie.su.domains/ElemStatLearn/datasets/SAheart.data\"\n",
    "\n",
    "# Load the SAheart dataset\n",
    "df = pd.read_csv(url, index_col='row.names')\n",
    "\n",
    "# Convert binary text data to numbered categories\n",
    "df['famhist'] = pd.Categorical(df['famhist']).codes\n",
    "\n",
    "# Extract the target attribute, and remove it from the training data\n",
    "y = np.asarray(np.asmatrix(df[\"typea\"].values).T).squeeze()\n",
    "df = df.drop(columns=[\"typea\"])\n",
    "\n",
    "# Attribute names\n",
    "attributeNames = list(map(lambda x: x.capitalize(), df.columns.tolist()))\n",
    "\n",
    "# Convert the training data to a numpy array\n",
    "X = df.to_numpy()\n",
    "N, M = X.shape\n",
    "\n",
    "X = zscore(X, ddof=1)  # Mean = 0, Std = 1\n",
    "y = zscore(y, ddof=1)  # Mean = 0, Std = 1\n",
    "\n",
    "# ---\n",
    "# End of data loading\n",
    "# ---\n",
    "\n",
    "\n",
    "# Add offset attribute\n",
    "X = np.concatenate((np.ones((X.shape[0], 1)), X), 1)\n",
    "attributeNames = [\"Offset\"] + attributeNames\n",
    "M = M + 1\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 10\n",
    "CV = model_selection.KFold(K, shuffle=True)\n",
    "# CV = model_selection.KFold(K, shuffle=False)\n",
    "\n",
    "lambda_count = 20\n",
    "\n",
    "# Values of lambda\n",
    "lambdas = np.logspace(0, 4, lambda_count)\n",
    "n_hidden_units_range = range(1, 30)\n",
    "max_iter = 10000\n",
    "\n",
    "#Actual y-s\n",
    "y_true = []\n",
    "\n",
    "# Linear regression\n",
    "lr_error_train = np.empty((K, 1))\n",
    "lr_error_test = np.empty((K, 1))\n",
    "best_lambda = np.empty((K, 1))\n",
    "y_est_lr = []\n",
    "\n",
    "# ANN\n",
    "ann_error_train = np.empty((K, 1))\n",
    "ann_error_test = np.empty((K, 1))\n",
    "best_hidden_units = np.empty((K, 1))\n",
    "y_est_ann = []\n",
    "\n",
    "# Baseline\n",
    "baseline_error_test = np.empty((K, 1))\n",
    "y_est_base = []\n",
    "\n",
    "\n",
    "w_rlr = np.empty((M, K))\n",
    "mu = np.empty((K, M - 1))\n",
    "sigma = np.empty((K, M - 1))\n",
    "w_noreg = np.empty((M, K))\n",
    "\n",
    "k = 0\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    innerCV = model_selection.KFold(K, shuffle=True)\n",
    "\n",
    "    y_true.append(y_test)\n",
    "\n",
    "\n",
    "    # ----\n",
    "    # Linear regression\n",
    "    # ----\n",
    "\n",
    "    (   opt_val_err,\n",
    "        opt_lambda,\n",
    "        mean_w_vs_lambda,\n",
    "        train_err_vs_lambda,\n",
    "        test_err_vs_lambda,\n",
    "    ) = rlr_validate_custom(X_train, y_train, lambdas, K, innerCV)\n",
    "\n",
    "    # Standardize outer fold based on training set, and save the mean and standard\n",
    "    # deviations since they're part of the model (they would be needed for\n",
    "    # making new predictions) - for brevity we won't always store these in the scripts\n",
    "    mu[k, :] = np.mean(X_train[:, 1:], 0)\n",
    "    sigma[k, :] = np.std(X_train[:, 1:], 0)\n",
    "\n",
    "    X_train[:, 1:] = (X_train[:, 1:] - mu[k, :]) / sigma[k, :]\n",
    "    X_test[:, 1:] = (X_test[:, 1:] - mu[k, :]) / sigma[k, :]\n",
    "\n",
    "    Xty = X_train.T @ y_train\n",
    "    XtX = X_train.T @ X_train\n",
    "\n",
    "    # Estimate weights for the optimal value of lambda, on entire training set\n",
    "    lambdaI = opt_lambda * np.eye(M)\n",
    "    lambdaI[0, 0] = 0  # Do no regularize the bias term\n",
    "    w_rlr[:, k] = np.linalg.solve(XtX + lambdaI, Xty).squeeze()\n",
    "\n",
    "    # Compute mean squared error with regularization with optimal lambda\n",
    "    lr_error_train[k] = (\n",
    "        np.square(y_train - X_train @ w_rlr[:, k]).sum(axis=0) / y_train.shape[0]\n",
    "    )\n",
    "    lr_error_test[k] = (\n",
    "        np.square(y_test - X_test @ w_rlr[:, k]).sum(axis=0) / y_test.shape[0]\n",
    "    )\n",
    "    best_lambda[k] = opt_lambda\n",
    "    y_est_lr.append(X_test @ w_rlr[:, k])\n",
    "\n",
    "    # ----\n",
    "    # ANN\n",
    "    # ----\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    models = np.empty((len(n_hidden_units_range),), dtype=object)\n",
    "\n",
    "    # Generate out models with different number of hidden units\n",
    "    for i, n_hidden_units in enumerate(n_hidden_units_range):\n",
    "        model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(M, n_hidden_units),  # Input layer\n",
    "            torch.nn.Tanh(),  # Hidden activation (ReLU is also good)\n",
    "            torch.nn.Linear(n_hidden_units, 1)   # Output layer (NO SIGMOID for regression)\n",
    "        )\n",
    "        models[i] = model\n",
    "\n",
    "    (\n",
    "        opt_val_err,\n",
    "        opt_model_index,\n",
    "        opt_model,\n",
    "        opt_network,\n",
    "        train_err_vs_lambda,\n",
    "        test_err_vs_lambda\n",
    "        #This does a folding cross-validation\n",
    "    ) = ann_validate(torch.Tensor(X_train), torch.Tensor(y_train), models, loss_fn, 1, max_iter, K, innerCV)\n",
    "\n",
    "    #ann_error_train[k] = np.square(y_train-opt_network(torch.Tensor(X_train)).detach().numpy()).sum()/y_train.shape[0]\n",
    "    #ann_error_test[k] = np.square(y_train-opt_network(torch.Tensor(X_train)).detach().numpy()).sum()/y_train.shape[0]\n",
    "\n",
    "    ann_error_train[k] = train_err_vs_lambda[opt_model_index]\n",
    "    ann_error_test[k] = test_err_vs_lambda[opt_model_index]\n",
    "    best_hidden_units[k] = n_hidden_units_range[opt_model_index]\n",
    "    y_est_ann.append(opt_network(torch.Tensor(X_test)).detach().numpy())\n",
    "\n",
    "    # ----\n",
    "    # Baseline\n",
    "    # ----\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Compute the mean of y_train as the baseline prediction\n",
    "    y_baseline = np.mean(y_train)\n",
    "\n",
    "    # Predict the same mean value for all test samples\n",
    "    y_pred_baseline = np.full_like(y_test, y_baseline)\n",
    "\n",
    "    # Compute and store the MSE\n",
    "    mse = mean_squared_error(y_test, y_pred_baseline)\n",
    "    baseline_error_test[k] = mse\n",
    "    y_est_base.append(y_pred_baseline)\n",
    "\n",
    "\n",
    "    k += 1\n"
   ],
   "id": "a038ce12b7806ffc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([373])) that is different to the input size (torch.Size([373, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "5it [00:46,  9.25s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:29,  8.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([373])) that is different to the input size (torch.Size([373, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "5it [00:44,  9.23s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:34,  9.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:54,  8.97s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:28,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:53,  9.02s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:33,  9.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:56,  9.40s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:31,  9.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:57,  9.10s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:28,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:49,  8.46s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:23,  8.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:49,  8.27s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:21,  8.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:51,  8.55s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:28,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "   (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=1, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=2, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=3, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=4, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=5, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=6, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=7, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=9, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=9, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=10, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=11, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=11, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=12, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=13, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=13, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=14, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=14, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=15, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=15, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=16, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=17, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=17, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=18, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=18, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=19, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=19, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=20, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=21, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=22, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=22, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=23, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=23, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=24, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=24, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=25, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=25, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=26, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=26, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=27, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=27, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=28, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=28, out_features=1, bias=True)\n",
      " )\n",
      " Sequential(\n",
      "   (0): Linear(in_features=10, out_features=29, bias=True)\n",
      "   (1): Tanh()\n",
      "   (2): Linear(in_features=29, out_features=1, bias=True)\n",
      " )                                                        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/ann_validate.py:241: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n",
      "6it [00:48,  8.32s/it]/Users/kostyalbalint/Documents/Egyetem/MSC/1.st Semester/IntroductionToMachineLearning/Intro-to-MI-Project_1/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "10it [01:24,  8.49s/it]\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:59:53.408609Z",
     "start_time": "2025-04-08T15:59:53.399496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = pd.DataFrame({\n",
    "    \"h\" : best_hidden_units.flatten(),\n",
    "    \"ann_error_test\": ann_error_test.flatten(),\n",
    "\n",
    "    \"lambda\": best_lambda.flatten(),\n",
    "    \"lr_error_test\": lr_error_test.flatten(),\n",
    "\n",
    "    \"baseline_error_test\": baseline_error_test.flatten(),\n",
    "})\n",
    "results"
   ],
   "id": "606c6651a5c81d4c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      h  ann_error_test      lambda  lr_error_test  baseline_error_test\n",
       "0   9.0        0.981690   78.475997       1.095045             1.111682\n",
       "1  20.0        0.997443   78.475997       1.014643             0.998448\n",
       "2   5.0        1.024234  127.427499       0.739055             0.748277\n",
       "3   6.0        1.000396   29.763514       0.988991             0.948298\n",
       "4  17.0        0.991316   78.475997       0.990541             1.057561\n",
       "5  23.0        0.988164  127.427499       1.026781             1.053704\n",
       "6  13.0        1.000706  335.981829       0.890256             0.917386\n",
       "7  10.0        0.977799  127.427499       1.140282             1.186476\n",
       "8  14.0        0.982276   78.475997       1.100426             1.172839\n",
       "9  11.0        1.013012   78.475997       0.790712             0.838251"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>ann_error_test</th>\n",
       "      <th>lambda</th>\n",
       "      <th>lr_error_test</th>\n",
       "      <th>baseline_error_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.981690</td>\n",
       "      <td>78.475997</td>\n",
       "      <td>1.095045</td>\n",
       "      <td>1.111682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.997443</td>\n",
       "      <td>78.475997</td>\n",
       "      <td>1.014643</td>\n",
       "      <td>0.998448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.024234</td>\n",
       "      <td>127.427499</td>\n",
       "      <td>0.739055</td>\n",
       "      <td>0.748277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000396</td>\n",
       "      <td>29.763514</td>\n",
       "      <td>0.988991</td>\n",
       "      <td>0.948298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.991316</td>\n",
       "      <td>78.475997</td>\n",
       "      <td>0.990541</td>\n",
       "      <td>1.057561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.988164</td>\n",
       "      <td>127.427499</td>\n",
       "      <td>1.026781</td>\n",
       "      <td>1.053704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.000706</td>\n",
       "      <td>335.981829</td>\n",
       "      <td>0.890256</td>\n",
       "      <td>0.917386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.977799</td>\n",
       "      <td>127.427499</td>\n",
       "      <td>1.140282</td>\n",
       "      <td>1.186476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.982276</td>\n",
       "      <td>78.475997</td>\n",
       "      <td>1.100426</td>\n",
       "      <td>1.172839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.013012</td>\n",
       "      <td>78.475997</td>\n",
       "      <td>0.790712</td>\n",
       "      <td>0.838251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:00:15.447357Z",
     "start_time": "2025-04-08T16:00:15.444630Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|cc|cc|c}\n",
      "\\toprule\n",
      "\\textbf{Outer fold} & \\multicolumn{2}{c|}{\\textbf{ANN}} & \\multicolumn{2}{c|}{\\textbf{Linear regression}} & \\textbf{baseline} \\\\\n",
      "$i$ & $h_i^*$ & $E_i^{\\text{test}}$ & $\\lambda_i^*$ & $E_i^{\\text{test}}$ & $E_i^{\\text{test}}$ \\\\\n",
      "\\midrule\n",
      "1 & 9.0 & 0.982 & 78.48 & 1.095 & 1.112 \\\\\n",
      "2 & 20.0 & 0.997 & 78.48 & 1.015 & 0.998 \\\\\n",
      "3 & 5.0 & 1.024 & 127.43 & 0.739 & 0.748 \\\\\n",
      "4 & 6.0 & 1.000 & 29.76 & 0.989 & 0.948 \\\\\n",
      "5 & 17.0 & 0.991 & 78.48 & 0.991 & 1.058 \\\\\n",
      "6 & 23.0 & 0.988 & 127.43 & 1.027 & 1.054 \\\\\n",
      "7 & 13.0 & 1.001 & 335.98 & 0.890 & 0.917 \\\\\n",
      "8 & 10.0 & 0.978 & 127.43 & 1.140 & 1.186 \\\\\n",
      "9 & 14.0 & 0.982 & 78.48 & 1.100 & 1.173 \\\\\n",
      "10 & 11.0 & 1.013 & 78.48 & 0.791 & 0.838 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "execution_count": 48,
   "source": [
    "latex_table = r\"\"\"\\begin{tabular}{c|cc|cc|c}\n",
    "\\toprule\n",
    "\\textbf{Outer fold} & \\multicolumn{2}{c|}{\\textbf{ANN}} & \\multicolumn{2}{c|}{\\textbf{Linear regression}} & \\textbf{baseline} \\\\\n",
    "$i$ & $h_i^*$ & $E_i^{\\text{test}}$ & $\\lambda_i^*$ & $E_i^{\\text{test}}$ & $E_i^{\\text{test}}$ \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for i, row in results.iterrows():\n",
    "    latex_table += f\"{i+1} & {row['h']} & {row['ann_error_test']:.3f} & {row['lambda']:.2f} & {row['lr_error_test']:.3f} & {row['baseline_error_test']:.3f} \\\\\\\\\\n\"\n",
    "\n",
    "latex_table += r\"\\bottomrule\" + \"\\n\" + r\"\\end{tabular}\"\n",
    "print(latex_table)\n"
   ],
   "id": "7e803c2be80e33ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:13:36.829073Z",
     "start_time": "2025-04-08T16:13:36.815801Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 51,
   "source": [
    "from dtuimldmtools.statistics.statistics import ttest_twomodels\n",
    "import numpy as np\n",
    "\n",
    "# Compute the Jeffreys interval\n",
    "alpha = 0.05\n",
    "rho = 1/K\n",
    "\n",
    "# Convert lists to numpy arrays and stack them properly\n",
    "y_true_array = np.concatenate(y_true).ravel()\n",
    "y_est_ANN_array = np.concatenate(y_est_ann).ravel()\n",
    "y_est_LR_array = np.concatenate(y_est_lr).ravel()\n",
    "y_est_base_array = np.concatenate(y_est_base).ravel()\n",
    "\n",
    "def run_ttest(y_true, y_A, y_B):\n",
    "    mean_diff, confidence_interval, p_value =  ttest_twomodels(y_true, y_A, y_B, alpha=alpha)\n",
    "    return mean_diff, confidence_interval, p_value\n",
    "\n",
    "# Perform t-tests\n",
    "mean_diff_ANN_LR, CI_ANN_LR, p_ANN_LR = run_ttest(y_true_array, y_est_ANN_array, y_est_LR_array)\n",
    "mean_diff_ANN_base, CI_ANN_base, p_ANN_base = run_ttest(y_true_array, y_est_ANN_array, y_est_base_array)\n",
    "mean_diff_LR_base, CI_LR_base, p_LR_base = run_ttest(y_true_array, y_est_LR_array, y_est_base_array)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Comparison\": [\"ANN vs LR\", \"ANN vs Baseline\", \"LR vs Baseline\"],\n",
    "    \"Mean Difference\": [mean_diff_ANN_LR, mean_diff_ANN_base, mean_diff_LR_base],\n",
    "    \"Confidence Interval Min\": [CI_ANN_LR[0], CI_ANN_base[0], CI_LR_base[0]],\n",
    "    \"Confidence Interval Max\": [CI_ANN_LR[1], CI_ANN_base[1], CI_LR_base[1]],\n",
    "    \"p-value\": [p_ANN_LR, p_ANN_base, p_LR_base]\n",
    "})"
   ],
   "id": "f771763f6abc7930"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:13:37.924599Z",
     "start_time": "2025-04-08T16:13:37.920397Z"
    }
   },
   "cell_type": "code",
   "source": "print(results_df.to_latex())",
   "id": "6431a997e20cbe42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      " & Comparison & Mean Difference & Confidence Interval Min & Confidence Interval Max & p-value \\\\\n",
      "\\midrule\n",
      "0 & ANN vs LR & 0.011330 & -0.005091 & 0.027750 & 0.175793 \\\\\n",
      "1 & ANN vs Baseline & 0.003649 & -0.000059 & 0.007357 & 0.053741 \\\\\n",
      "2 & LR vs Baseline & -0.007681 & -0.023887 & 0.008526 & 0.352174 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:19:04.386818Z",
     "start_time": "2025-04-08T16:19:04.325964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(results_df[\"Comparison\"], results_df[\"Mean Difference\"],\n",
    "             yerr=[results_df[\"Mean Difference\"] - results_df[\"Confidence Interval Min\"], results_df[\"Confidence Interval Max\"] - results_df[\"Mean Difference\"]],\n",
    "             fmt='o', capsize=5, capthick=2, color='teal', ecolor='gray')\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "plt.title(\"Mean Differences with 95% Confidence Intervals\")\n",
    "plt.ylabel(\"Mean Difference\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Annotate p-values\n",
    "for i, row in results_df.iterrows():\n",
    "    plt.text(i, row[\"Mean Difference\"] + 0.002, f\"p = {row['p-value']:.3f}\", ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "f85aeeb6de1a5085",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 60
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
